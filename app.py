import streamlit as st
import cv2
import numpy as np
from PIL import Image
import io
import streamlit as st
import cv2
import numpy as np
from PIL import Image
import io
import os
import urllib.request
import random

st.set_page_config(page_title="ğŸª GÆ°Æ¡ng tháº§n Pixel â€“ Biá»ƒu cáº£m siÃªu hÃ i", layout="wide")


st.title("ğŸª GÆ°Æ¡ng tháº§n Pixel â€“ PhÃ¢n tÃ­ch áº£nh hÃ i hÆ°á»›c")

uploaded_file = st.file_uploader("ğŸ“¸ Vui lÃ²ng táº£i áº£nh selfie cá»§a báº¡n:", type=["jpg", "jpeg", "png"])

def analyze_skin_tone(hsv_img):
    h, s, v = cv2.split(hsv_img)
    h_mean = np.mean(h)
    s_mean = np.mean(s)
    v_mean = np.mean(v)
    if h_mean < 20 and s_mean > 100:
        return "red"
    elif h_mean > 90 and v_mean > 150:
        return "pale"
    elif s_mean < 60:
        return "pale"
    else:
        return "normal"

def simulate_burnout_effect(image_pil):
    buffer = io.BytesIO()
    image_pil.save(buffer, format="JPEG", quality=5)
    buffer.seek(0)
    compressed_img = Image.open(buffer)
    return compressed_img

def generate_diagnosis(sharpness_score, skin_tone):
    messages = []
    if sharpness_score > 5.0:
        messages.append("ğŸ˜¬ HÃ¬nh nhÆ° báº¡n Ä‘ang... cÄƒng nhÆ° dÃ¢y Ä‘Ã n!")
    else:
        messages.append("ğŸ˜Œ Báº¡n cÃ³ váº» Ä‘ang thÆ° giÃ£n vÃ  chill~")
    if skin_tone == "pale":
        messages.append("ğŸ˜´ Da báº¡n nhá»£t nháº¡t ghÃª, thiáº¿u ngá»§ khÃ´ng Ä‘Ã³?")
    elif skin_tone == "red":
        messages.append("ğŸ˜¡ Da Ä‘á» rá»±c váº­y, má»›i Ä‘i cÃ£i lá»™n ai Ã ?")
    elif skin_tone == "normal":
        messages.append("ğŸ˜ MÃ u da á»•n Ã¡p, tháº§n thÃ¡i á»•n Ä‘á»‹nh Ä‘Ã³ nhen!")
    final_message = "\n".join(messages)
    return final_message

if uploaded_file:
    image = Image.open(uploaded_file).convert("RGB")
    img_np = np.array(image)
    img_bgr = cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR)
    img_gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)
    img_hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)

    st.image(image, caption="ğŸ“· áº¢nh gá»‘c",width=512)
    st.image(img_gray, caption="ğŸ” áº¢nh Grayscale", channels="GRAY", width=512)
    st.image(cv2.cvtColor(img_hsv, cv2.COLOR_HSV2RGB), caption="ğŸ¨ áº¢nh HSV", width=512)
    st.success("âœ… ÄÃ£ chuyá»ƒn Ä‘á»•i thÃ nh cÃ´ng sang Grayscale vÃ  HSV!")

    blurred = cv2.GaussianBlur(img_gray, (9, 9), 0)
    sobelx = cv2.Sobel(blurred, cv2.CV_64F, 1, 0, ksize=5)
    sobely = cv2.Sobel(blurred, cv2.CV_64F, 0, 1, ksize=5)
    sobel_combined = cv2.magnitude(sobelx, sobely)
    sobel_combined = np.uint8(np.clip(sobel_combined, 0, 255))

    st.subheader("ğŸ”¬ Spatial Domain Filtering")
    st.image(blurred, caption="âœ¨ Gaussian Blurred Image", channels="GRAY", width=512)
    st.image(sobel_combined, caption="ğŸ§  Sobel Edge Detection", channels="GRAY", width=512)

    dft = cv2.dft(np.float32(img_gray), flags=cv2.DFT_COMPLEX_OUTPUT)
    dft_shift = np.fft.fftshift(dft)
    magnitude = cv2.magnitude(dft_shift[:, :, 0], dft_shift[:, :, 1])
    spectrum = 20 * np.log(magnitude + 1)
    spectrum_norm = cv2.normalize(spectrum, None, 0, 255, cv2.NORM_MINMAX)
    spectrum_uint8 = np.uint8(spectrum_norm)
    sharpness_score = np.mean(spectrum)

    st.subheader("âš¡ Frequency Domain Analysis")
    st.image(spectrum_uint8, caption="ğŸ“ˆ Frequency Spectrum (DFT)", width=512)

    if sharpness_score < 20:
        stress_level = "ğŸ§˜â€â™‚ï¸ ThÆ° giÃ£n nhÆ° nÆ°á»›c suá»‘i!"
    elif sharpness_score < 50:
        stress_level = "ğŸ˜ Táº¡m á»•n, nhÆ°ng hÆ¡i thiáº¿u caffeine!"
    else:
        stress_level = "ğŸ˜µâ€ğŸ’« HÃ¬nh nhÆ° báº¡n Ä‘ang... cÄƒng nhÆ° dÃ¢y Ä‘Ã n!"
    st.markdown(f"**Stress Level Estimate:** `{stress_level}`")

    skin_tone = analyze_skin_tone(img_hsv)
    skin_message = {
        "red": "ğŸ”´ CÃ³ váº» báº¡n Ä‘ang nÃ³ng giáº­n hoáº·c stress?",
        "pale": "ğŸ§Š Báº¡n hÆ¡i tÃ¡i nhá»£t... thiáº¿u vitamin D khÃ´ng nÃ¨?",
        "normal": "ğŸŒˆ Da báº¡n khÃ¡ cÃ¢n báº±ng, chill nha!"
    }
    st.markdown(f"**Skin Tone Mood**: {skin_message[skin_tone]}")

    st.markdown("### ğŸ”¥ Burnout Simulator (Compressed Image)")
    compressed_image = simulate_burnout_effect(image)
    st.image(compressed_image, caption="ğŸ“‰ MÃ´ phá»ng tráº¡ng thÃ¡i burnout", width=512)
    st.warning("ğŸ§  NÃ£o báº¡n cÃ³ váº» Ä‘ang 'nÃ³ng mÃ¡y' Ä‘áº¥y... nghá»‰ má»™t tÃ­ Ä‘i nÃ¨!")

    diagnosis = generate_diagnosis(sharpness_score, skin_tone)
    st.markdown("### ğŸ§  Pixel Mirror Diagnosis")
    st.success(diagnosis)

# ========== TÃCH Há»¢P NHáº¬N DIá»†N BIá»‚U Cáº¢M & CHáº¨N ÄOÃN HÃ€I HÆ¯á»šC ========== #




# Táº£i model náº¿u chÆ°a cÃ³
if not os.path.exists("emotion-ferplus-8.onnx"):
    urllib.request.urlretrieve("https://github.com/onnx/models/raw/main/validated/vision/body_analysis/emotion_ferplus/model/emotion-ferplus-8.onnx", "emotion-ferplus-8.onnx")
if not os.path.exists("deploy.prototxt"):
    urllib.request.urlretrieve("https://raw.githubusercontent.com/opencv/opencv/master/samples/dnn/face_detector/deploy.prototxt", "deploy.prototxt")
if not os.path.exists("res10_300x300_ssd_iter_140000_fp16.caffemodel"):
    urllib.request.urlretrieve("https://github.com/spmallick/learnopencv/raw/master/FaceDetectionComparison/models/res10_300x300_ssd_iter_140000_fp16.caffemodel", "res10_300x300_ssd_iter_140000_fp16.caffemodel")

emotion_labels = ["neutral", "happiness", "surprise", "sadness", "anger", "disgust", "fear", "contempt"]
emoji_dict = {
    "neutral": "ğŸ˜", "happiness": "ğŸ˜„", "surprise": "ğŸ˜²", "sadness": "ğŸ˜¢",
    "anger": "ğŸ˜ ", "disgust": "ğŸ¤¢", "fear": "ğŸ˜±", "contempt": "ğŸ™„"
}

# HÆ¡n 100 cÃ¢u cháº©n Ä‘oÃ¡n, ngáº«u nhiÃªn
fun_diagnosis_dict = {
    "neutral": [
        "Poker face trÃ¬nh Ä‘á»™ thÆ°á»£ng thá»«a.",
        "Báº¡n Ä‘ang suy ngáº«m vá» vÅ© trá»¥ vÃ  cuá»™c sá»‘ng?",
        "GÆ°Æ¡ng máº·t nÃ y chuyÃªn trá»‹ há»™i nghá»‹ vÃ  há»p hÃ nh.",
        "Báº¡n cÃ³ Ä‘ang nghÄ© vá» bá»¯a tá»‘i khÃ´ng?",
        "TÃ¢m há»“n láº¡c vÃ o cÃµi thiá»n?",
        "Váº» máº·t nÃ y lÃ  khi tháº¥y deadline mÃ  váº«n bÃ¬nh tháº£n.",
        "CÃ¢n báº±ng hÆ¡n cáº£ thiá»n sÆ°.",
        "Máº·t cá»§a ngÆ°á»i khÃ´ng quan tÃ¢m drama.",
        "Tháº§n thÃ¡i láº¡nh nhÆ° bÄƒng.",
        "Giao diá»‡n Ä‘ang cáº­p nháº­t cáº£m xÃºc...",
        "TrÃ­ tuá»‡ nhÃ¢n táº¡o cÅ©ng khÃ´ng Ä‘oÃ¡n Ä‘Æ°á»£c báº¡n nghÄ© gÃ¬.",
        "Cháº¯c báº¡n Ä‘ang Ä‘á»©ng hÃ¬nh 5 giÃ¢y rá»“i."
    ],
    "happiness": [
        "Báº¡n Ä‘ang tá»a sÃ¡ng nhÆ° idol K-pop!",
        "CÆ°á»i tÆ°Æ¡i nhÆ° mÃ¹a xuÃ¢n vá»!",
        "Vá»«a Ä‘Æ°á»£c Ä‘iá»ƒm cao hay Ä‘Æ°á»£c Äƒn mÃ³n yÃªu thÃ­ch váº­y?",
        "GÆ°Æ¡ng máº·t cá»§a ngÆ°á»i vá»«a trÃºng vÃ© sá»‘!",
        "CÆ°á»i mÃ  nhÆ° quáº£ng cÃ¡o kem Ä‘Ã¡nh rÄƒng.",
        "Ná»¥ cÆ°á»i nÃ y cÃ³ thá»ƒ chá»¯a lÃ nh trÃ¡i tim tan vá»¡.",
        "SÃ¡ng bá»«ng cáº£ khung hÃ¬nh!",
        "Máº·t vui nhÆ° khi nghe tá»›i giá» tan há»c.",
        "Cháº¯c cháº¯n cÃ³ tin tá»‘t vá»«a Ä‘áº¿n!",
        "Ai Ä‘Ã³ Ä‘ang yÃªu Ä‘á»i dá»¯ láº¯m!",
        "Báº¡n vá»«a lÃ m ai Ä‘Ã³ vui chá»‰ vá»›i ná»¥ cÆ°á»i.",
        "CÆ°á»i mÃ  khÃ´ng tháº¥y rÄƒng lÃ  vui tháº­t sá»±!"
    ],
    "surprise": [
        "Báº¡n vá»«a tháº¥y Ä‘iá»u gÃ¬ Ä‘Ã³ cá»±c sá»‘c?",
        "Máº¯t chá»¯ O, miá»‡ng chá»¯ A chÃ­nh hiá»‡u!",
        "á»¦a gÃ¬ váº­y trá»i???",
        "Giá»‘ng nhÆ° vá»«a phÃ¡t hiá»‡n crush cÅ©ng thÃ­ch mÃ¬nh!",
        "Biá»ƒu cáº£m khi má»Ÿ phong bÃ¬ lÃ¬ xÃ¬ tháº¥y 500k.",
        "CÃ³ váº» báº¡n vá»«a phÃ¡t hiá»‡n ra bÃ­ máº­t vÅ© trá»¥!",
        "Máº·t nhÆ° vá»«a nhá»› ra bá» quÃªn ná»“i cÆ¡m.",
        "Cáº£m xÃºc 'Æ  kÃ¬a' Ä‘ang hiá»‡n há»¯u trÃªn máº·t báº¡n!",
        "Báº¡n vá»«a nghe tin: ngÃ y mai Ä‘Æ°á»£c nghá»‰ há»c!",
        "Sá»± báº¥t ngá» Ä‘ang xÃ¢m chiáº¿m linh há»“n báº¡n.",
        "Báº¡n sáº¯p hÃ©t lÃªn Ä‘Ãºng khÃ´ng?",
        "Cáº£m xÃºc khÃ´ng thá»ƒ Ä‘á»‹nh nghÄ©a Ä‘Æ°á»£c!"
    ],
    "sadness": [
        "Ã”i buá»“n nhÆ° lÃ¡ rÆ¡i mÃ¹a thu...",
        "Báº¡n cÃ³ cáº§n má»™t cÃ¡i Ã´m khÃ´ng?",
        "TÃ¢m tráº¡ng nhÆ° bá»‹ Ä‘iá»ƒm tháº¥p mÃ´n yÃªu thÃ­ch?",
        "GÆ°Æ¡ng máº·t tháº¥t tÃ¬nh Ã ?",
        "Báº¡n cÃ³ Ä‘ang nhá»› mÃ¨o cÅ© khÃ´ng?",
        "Tá»‘i nay báº¡n cáº§n 1 ly trÃ  sá»¯a an á»§i.",
        "NÃ©t buá»“n nhÆ° ca sÄ© hÃ¡t ballad.",
        "Buá»“n nhÆ°ng váº«n Ä‘áº¹p nha!",
        "Cháº¯c cháº¯n cÃ³ chuyá»‡n gÃ¬ Ä‘Ã³ xáº£y ra rá»“i.",
        "ÄÃ´i máº¯t ngáº¥n nÆ°á»›c nhÆ° sáº¯p mÆ°a.",
        "GÆ°Æ¡ng máº·t 'ngÃ y chá»§ nháº­t tá»‘i'.",
        "Buá»“n vÃ¬ háº¿t phim hay Ä‘á»ƒ xem Ä‘Ãºng khÃ´ng?"
    ],
    "anger": [
        "Báº¡n trÃ´ng nhÆ° Ä‘ang báº­t mode 'Ä‘á»«ng chá»c tui'!",
        "GÆ°Æ¡ng máº·t cá»§a ngÆ°á»i vá»«a bá»‹ spoil phim!",
        "Biá»ƒu cáº£m cá»§a dÃ¢n IT gáº·p bug 3 ngÃ y chÆ°a fix Ä‘Æ°á»£c.",
        "Báº¡n cáº§n trÃ  hay cáº§n Ä‘Ã¡?",
        "NÃ©t tá»©c giáº­n nÃ y Ä‘áº§y ná»™i lá»±c!",
        "Ai dÃ¡m chá»c báº¡n thÃ¬ toang rá»“i.",
        "Cháº¯c vá»«a Ä‘á»c comment vÃ´ duyÃªn?",
        "Sáº¯p hÃ³a Hulk Ä‘áº¿n nÆ¡i!",
        "CÃ¡u nhÆ°ng váº«n Ä‘Ã¡ng yÃªu nÃ¨!",
        "GÆ°Æ¡ng máº·t chá» cÃ  phÃª nhÆ°ng ngÆ°á»i ta pha trÃ .",
        "Thá»Ÿ sÃ¢u... hÃ­t vÃ o... thá»Ÿ ra...",
        "Äá»«ng Ä‘á»ƒ báº¡n nÃ y báº­t cháº¿ Ä‘á»™ chiáº¿n binh!"
    ],
    "disgust": [
        "Báº¡n vá»«a ngá»­i tháº¥y mÃ¹i gÃ¬ Ä‘Ã³ sai sai?",
        "Váº» máº·t khi Äƒn pháº£i mÃ­t sáº§u riÃªng mÃ  khÃ´ng thÃ­ch.",
        "Biá»ƒu cáº£m 'Æ¡ cÃ¡i gÃ¬ dáº¡???'",
        "NÃ©t máº·t nhÆ° Ä‘ang bá»‹ buá»™c nghe nháº¡c remix lÃºc sÃ¡ng sá»›m.",
        "Báº¡n vá»«a nhÃ¬n tháº¥y gÃ¬ gÃ¢y khÃ³ chá»‹u váº­y?",
        "TÃ´i tháº¥y báº¡n vá»«a Ä‘Ã¡nh giÃ¡ 1 sao trong lÃ²ng.",
        "GÆ°Æ¡ng máº·t pháº£n Ä‘á»‘i má»i thá»© xung quanh.",
        "Báº¡n Ä‘ang muá»‘n rá»i khá»i nÆ¡i nÃ y gáº¥p.",
        "Ãnh nhÃ¬n â€˜khÃ´ng thÃ¨m nÃ³i chuyá»‡nâ€™.",
        "CÃ³ pháº£i báº¡n vá»«a Ä‘á»c status quÃ¡ sáº¿n sÃºa?",
        "Báº¡n vá»«a nghe cÃ¢u chuyá»‡n toxic nÃ o Ä‘Ã³?",
        "ÄÃ¢y lÃ  pháº£n á»©ng Ä‘Ãºng khi gáº·p Ä‘á»“ Äƒn dá»Ÿ."
    ],
    "fear": [
        "Báº¡n vá»«a tháº¥y hÃ³a Ä‘Æ¡n tiá»n Ä‘iá»‡n Ä‘Ãºng khÃ´ng?",
        "Ãnh máº¯t lo láº¯ng cá»§a ngÆ°á»i Ä‘i thi khÃ´ng há»c bÃ i.",
        "GÆ°Æ¡ng máº·t tháº¥y deadline tá»›i gáº§n...",
        "Báº¡n trÃ´ng nhÆ° nghe tiáº¿ng máº¹ gá»i lÃºc chÆ¡i game.",
        "Báº¡n vá»«a tháº¥y con giÃ¡n bay Ä‘Ãºng khÃ´ng!?",
        "GÆ°Æ¡ng máº·t 'cháº¯c mÃ¬nh táº¯t báº¿p rá»“i Ä‘Ã³ ha...'",
        "Biá»ƒu cáº£m Ä‘áº§y lo Ã¢u, nhÆ°ng váº«n xinh!",
        "Äá»«ng sá»£, cÃ³ tÃ´i á»Ÿ Ä‘Ã¢y mÃ  ğŸ˜",
        "Báº¡n vá»«a nhá»› láº¡i chuyá»‡n cÅ© Ä‘Ã¡ng sá»£ Ã ?",
        "Sá»± hoang mang hiá»‡n rÃµ trÃªn gÆ°Æ¡ng máº·t!",
        "TÃ¢m tráº¡ng 'mÃ¬nh cÃ³ ná»™p bÃ i chÆ°a nhá»‰?'"
    ],
    "contempt": [
        "CÃ¡i nhÃ¬n khinh bá»‰ ráº¥t nháº¹ nhÆ°ng Ä‘áº§y sÃ¡t thÆ°Æ¡ng.",
        "Báº¡n Ä‘ang khinh nháº¹ ai Ä‘Ã³ Ä‘Ãºng khÃ´ng?",
        "Máº¯t báº¡n vá»«a láº­t nháº¹ má»™t vÃ²ng trÃ²n.",
        "GÆ°Æ¡ng máº·t â€˜tÃ´i hÆ¡n báº¡n á»Ÿ cÃ¡i tháº§n thÃ¡iâ€™.",
        "Báº¡n nhÆ° Ä‘ang Ä‘Ã³ng vai pháº£n diá»‡n láº¡nh lÃ¹ng.",
        "Cháº¯c báº¡n vá»«a nghe cÃ¢u chuyá»‡n khÃ´ng Ä‘Ã¡ng nghe.",
        "Ai Ä‘Ã³ vá»«a lÃ m báº¡n máº¥t kiÃªn nháº«n?",
        "CÃ¡i nhÃ¬n cá»§a ngÆ°á»i tá»«ng tráº£i vÃ  Ä‘Ã£ chÃ¡n drama.",
        "Báº¡n cáº§n cá»‘c trÃ  Ä‘Ã¡ cho bá»›t khinh ngÆ°á»i ta kÃ¬a ğŸ˜†",
        "NÃ©t máº·t nÃ y xá»©ng Ä‘Ã¡ng Ä‘á»©ng Ä‘áº§u há»™i Ä‘á»“ng!",
        "Báº¡n biáº¿t quÃ¡ nhiá»u vÃ  khÃ´ng muá»‘n nÃ³i ra.",
        "ÄÃ¢y lÃ  Ä‘á»‰nh cao cá»§a thÃ¡i Ä‘á»™ 'á»ª, tÃ´i biáº¿t rá»“i!'"
    ]
}

def detect_faces_dnn(image_bgr):
    net = cv2.dnn.readNetFromCaffe("deploy.prototxt", "res10_300x300_ssd_iter_140000_fp16.caffemodel")
    h, w = image_bgr.shape[:2]
    blob = cv2.dnn.blobFromImage(image_bgr, 1.0, (300, 300), (104.0, 177.0, 123.0))
    net.setInput(blob)
    detections = net.forward()
    faces = []
    for i in range(detections.shape[2]):
        confidence = detections[0, 0, i, 2]
        if confidence > 0.5:
            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])
            x1, y1, x2, y2 = box.astype(int)
            x1, y1 = max(0, x1), max(0, y1)
            x2, y2 = min(w, x2), min(h, y2)
            faces.append((x1, y1, x2 - x1, y2 - y1))
    return faces

def preprocess_face(face_img):
    face = cv2.cvtColor(face_img, cv2.COLOR_BGR2GRAY)
    face = cv2.resize(face, (64, 64))
    face = face.astype(np.float32)
    face = face[np.newaxis, np.newaxis, :, :]
    return face

def predict_emotion(face_blob):
    net = cv2.dnn.readNetFromONNX("emotion-ferplus-8.onnx")
    net.setInput(face_blob)
    output = net.forward()
    emotion_idx = np.argmax(output)
    return emotion_labels[emotion_idx], float(np.max(output))

if uploaded_file:
    image = Image.open(uploaded_file).convert("RGB")
    img_np = np.array(image)
    img_bgr = cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR)
    st.image(image, caption="ğŸ“· áº¢nh gá»‘c", width=512)

    faces = detect_faces_dnn(img_bgr)

    if not faces:
        st.warning("ğŸ˜¶ KhÃ´ng tÃ¬m tháº¥y khuÃ´n máº·t nÃ o.")
    else:
        st.success(f"ÄÃ£ phÃ¡t hiá»‡n {len(faces)} khuÃ´n máº·t!")
        col1, col2 = st.columns(2)
        annotated_img = img_bgr.copy()

        for idx, (x, y, w, h) in enumerate(faces):
            face_crop = img_bgr[y:y+h, x:x+w]
            if face_crop.shape[0] < 10 or face_crop.shape[1] < 10:
                continue

            blob = preprocess_face(face_crop)
            emotion, score = predict_emotion(blob)

            cv2.rectangle(annotated_img, (x, y), (x+w, y+h), (0, 255, 0), 2)
            cv2.putText(annotated_img, f"{emotion}", (x, y - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

            fun_comment = random.choice(fun_diagnosis_dict.get(emotion, ["Biá»ƒu cáº£m khÃ³ hiá»ƒu quÃ¡! ğŸ¤”"]))
            with col1 if idx % 2 == 0 else col2:
                st.image(cv2.cvtColor(face_crop, cv2.COLOR_BGR2RGB),
                         caption=f"Máº·t #{idx+1}: {emotion} {emoji_dict[emotion]} ({score:.2f})\n{fun_comment}",
                         width=512)

        st.image(cv2.cvtColor(annotated_img, cv2.COLOR_BGR2RGB),
                 caption="ğŸ“¸ Gáº¯n nhÃ£n biá»ƒu cáº£m vui nhá»™n", width=512)
